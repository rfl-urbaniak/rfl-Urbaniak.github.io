---
layout: page
title: False positives
output:
  #  md_document:
  github_document:
    pandoc_args: --mathjax
#    variant: markdown_github
  preserve_yaml: true
bibliography: [../references/referencesMRbook.bib]
csl: [../references/apa-6th-edition.csl]
---

```{r , echo = FALSE, eval = TRUE}
#knitr::opts_knit$set(base.dir = "/home/rafal/L2/L2projects/backtesting",
knitr::opts_knit$set(base.dir = "/home/rafal/UG/UGprojects/rfl-urbaniak.github.io",
base.url = "https://rfl-urbaniak.github.io/")
knitr::opts_chunk$set(fig.path = "images/")
```




Hopefully, having convinced the reader that the false positive probability is non-negligible, I can now move to a probabilistic approach to the impact such probability can have on the value of evidence. Since I will use the likelihood ratio, a fairly standard measure of evidential strength, I first explain this notion, then explain one relevant formula and its derivation, leaving another perspective to another post. 


The \textbf{likelihood ratio} is a comparative measure of whether evidence $E$ supports a hypothesis $H$ more than a competing hypothesis $H'$, in symbols:
\begin{align}
\label{eq:LR}
\mathsf{LR}(E,H,H') & = \frac{\pr{E \vert H}}{\pr{E \vert H'}}.
\end{align}

If the evidence supports $H$ more than $H'$, the ratio would be above one, and if the evidence supports $H'$ more than $H$, the ratio would be below one.  So, support levels correspond to deviations from one.  The greater the likelihood ratio (for values above one), the stronger the evidence in favor of $H$ as contrasted with $H'$. The smaller the likelihood ratio (for values below one), the stronger the evidence in favor of the competing hypothesis $H'$ as contrasted with $H$.


Experts sometimes testify by offering the likelihood ratio as a measure of the strength of the evidence.  An expert, for instance, may testify that the blood-staining on the jacket of the defendant is ten times more likely to be seen if the wearer of the jacket hit the victim (prosecutor's hypothesis) rather than if he did not (defense's hypothesis) [@aitken2010fundamentals, p. 38].  Experts are typically 
advised not to comment  on the posterior odds given the evidence.
As this formulation of the Bayes's theorem makes clear, an assessment of the posterior odds will require a judgment about the prior odds, and the latter lies beyond the competence of an expert. A prominent forensic scientist recommends that  experts `not trespass on the province of the jury by commenting directly on the accused's guilt or innocence, 
\dots and should generally confine their testimony to presenting the likelihood of their evidence under competing propositions' [@aitken2010fundamentals, p. 42]. 

Now, let us follow @aitken2003probability in investigating  its impact on the likelihood ratio of the DNA match. We just add a bit more details to the derivation they present for the sake of clarity. For simplicity we stil assume that the false negative probability is 0, that is, that if the match is real, it will be reported with certainty. We abbreviate:

\begin{center} \hspace{10mm}
\begin{tabular}{lp{9cm}}
$S$ & The specimen comes from the suspect. \\
$R$ & A match is reported. \\
$M$ & There is a true match.
\end{tabular}
\end{center}

The formula we will end up with is:

\begin{align}
\tag{FPP-LR} \mathsf{LR}(R, S, \n S) & = \frac{1}{RMP + [ FPP \times (1-RMP)]}
\end{align}
\noindent where RMP stands for the random match probability and FPP for the false positive probability. We will assume that whether a (lack of) match is reported is independent of whether it is coincidental,
\begin{align}
\label{eq:indOnS}
\pr{R \vert M \et S} & = \pr{R \vert M \et \n S} = \pr{R \vert M}
\\ \nonumber
\pr{R \vert \n M \et S} & = \pr{R \vert\n M \et \n S} = \pr{R \vert \n M},
\end{align}
\noindent  that the probability of true match if the suspect is a source is 1,
\begin{align}
\label{eq:ifSthenM}
\pr{M\vert S} = 1  \,\,\, \mbox{ so also } \,\,\, \pr{\n M \vert S}=0,
\end{align}
\noindent and that the probability that a true match is reported,
\begin{align}
\label{eq:fnNull}
\pr{R \vert M} & = 1.
\end{align}



Here, for simplicity we take the probability of a false negative to be null; in fact, some of the reasons for taking false positives seriously are also reasons to take false negatives seriously, but let's deal with one problem at a time (and in the end, the impact of a false positive risk will be clear from the way the formula will be derived). Now, let us rewrite the numerator of the LR by extending the conversation, rewriting the probabilities of conjunctions in terms of conditional probability and simplifying: 

\begin{align}
\label{eq:numer}
\pr{R\vert S} & = \frac{\pr{R\et S}}{\pr{S}} \\ \nonumber
& = \frac{\pr{R \et M \et S} + \pr{R \et \n M \et S}}
{\pr{S}}  \\ \nonumber
& = \frac{\pr{R \vert M \et S}\pr{M \vert S}\pr{S} + \pr{R \vert \n M \et S}\pr{\n M \vert S}\pr{S}}
{\pr{S}}  \\ \nonumber 
& = \pr{R \vert M \et S}\pr{M \vert S} + \pr{R \vert \n M \et S}\pr{\n M \vert S}
\end{align}

\noindent  Analogously, we can rewrite the denominator:
\begin{align}
\label{eq:denom}
\pr{R \vert \n S} & = \pr{R \vert M \et \n S}\pr{M \vert \n S} +
\pr{R \vert \n M \et \n S}\pr{\n M \vert \n S}
\end{align}

Putting \eqref{eq:numer} and \eqref{eq:denom} together, we have that:
\begin{align}
\label{eq:LRfp1}
\mathsf{LR}(R,S, \n S) & = \frac{\pr{R \vert M \et S}\pr{M \vert S} + \pr{R \vert \n M \et S}\pr{\n M \vert S}}
{\pr{R \vert M \et \n S}\pr{M \vert \n S} +
\pr{R \vert \n M \et \n S}\pr{\n M \vert \n S}}
\end{align}
Now, apply \eqref{eq:indOnS} in four places:
\begin{align}
\label{eq:LRfp2}
\mathsf{LR}(R,S, \n S) & = \frac{
\pr{R \vert M}\pr{M \vert S} + \pr{R \vert \n M}\pr{\n M \vert S}
}{
\pr{R \vert M }\pr{M \vert \n S} +
\pr{R \vert \n M}\pr{\n M \vert \n S}
}
\end{align}
Then, use \eqref{eq:ifSthenM} in the numerator:
\begin{align}
\label{eq:LRfp3}
\mathsf{LR}(R,S, \n S) & = \frac{
\pr{R \vert M} \times 1 + \pr{R \vert \n M}\times 0
}{
\pr{R \vert M }\pr{M \vert \n S} +
\pr{R \vert \n M}\pr{\n M \vert \n S}
}
\end{align}
Finally, \eqref{eq:fnNull} yields:
\begin{align}
\label{eq:LRfp4}
\mathsf{LR}(R,S, \n S) & = \frac{1}
{\pr{R \vert  M}\pr{ M \vert \n S} + \pr{R \vert \n M}\pr{\n M \vert \n S}}
\end{align}
Once we abbreviate $\pr{M\vert \n S}$ as RMP, $\pr{R \vert \n M}$ as FPP and $\pr{\n M \vert \n S}$, we arrive at the desired formula.


Now, let us illustrate this impact for the range of FPP between 0 and 0.05, for two values of RMP: $10^{-9}$ (often reported in the case of two single source samples over ten or more loci) and $10{^-3}$ (sometimes obtained by means of less discriminating tests when the comparison involves a mixed sample). 

\begin{figure}
```{r fig-fpplr,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", message = FALSE, warning = FALSE}
library(ggplot2)
library(ggthemes)
rmp9 <- 10e-9
rmp3 <- 10e-3
fpp <- seq(0,0.05, by = 0.001)

lr9 <- 1/(rmp9 + (fpp * (1-rmp9)))
lr3 <- 1/(rmp3 + (fpp * (1-rmp3)))

fppTable <- data.frame(fpp,   lr9,  lr3, ref = rep(16.8, length(fpp)))

library(tidyr)
fppTableLong <- gather(fppTable,line,value,c(lr9,lr3,ref), factor_key=TRUE)



ggplot(fppTableLong, aes(x=fpp,y=value, lty = line))+  geom_line()+ylim(c(0,400))+theme_tufte()+ylim(c(0,400))+ylab("Likelihood ratio")+xlab("False positive probability") +scale_linetype_manual(values = c(1,2,3),labels = 
              c(expression(paste("RMP=",10^{-9})),expression(paste("RMP=",10^{-3})),"reference at 16.8"))+ggtitle("Impact of false positive probability on likelihood ratio")+ 
  theme(legend.position = c(0.85,.7))
```
\label{fig:fpplr}
\caption{Impact of the false positive probability on the likelihood ratio for two values of RMP. The horizontal reference line is at 16.8, the likelihood reached at RMP=$10{^-3}$ for FPP=0.05. At the same value of FPP, the LR for RMP $10{^-9}$ is 20.}
\end{figure}




